# ðŸ“¦ GitHub Setup Guide

## Why Push to GitHub?

- âœ… **Version control** for your code
- âœ… **Easy sync** between Mac and Colab
- âœ… **Backup** of your pipeline
- âœ… **Share** with collaborators
- âœ… **Clone** directly in Colab

---

## ðŸš€ Quick Setup (5 minutes)

### Step 1: Create GitHub Repository

1. Go to [github.com](https://github.com)
2. Click **"+"** â†’ **"New repository"**
3. Settings:
   - Repository name: `plastic-type-classification`
   - Description: `Hyperspectral plastic classification using 1D CNN`
   - Visibility: **Private** (recommended) or Public
   - âŒ **Don't** initialize with README (we have one)
4. Click **"Create repository"**

---

### Step 2: Initialize Git (if not already done)

```bash
cd /Users/nawapong/Projects/plastic-type-classification

# Check if git is initialized
git status

# If not initialized, run:
git init
```

---

### Step 3: Add Files to Git

```bash
# Add all code files (data is excluded via .gitignore)
git add .

# Check what will be committed
git status

# Should show:
# - All .py files âœ“
# - All .md files âœ“
# - .ipynb file âœ“
# - config.py âœ“
# - .gitignore âœ“
#
# Should NOT show:
# - training_dataset/ âœ—
# - output/ âœ—
# - *.pth files âœ—
```

---

### Step 4: Create Initial Commit

```bash
git commit -m "Initial commit: Hyperspectral plastic classification pipeline

- 6 model architectures (CNN, ResNet, Deep, Inception, LSTM, Transformer)
- M4 GPU (MPS) support
- Google Colab notebook
- Complete training and inference pipeline
- Comprehensive documentation"
```

---

### Step 5: Push to GitHub

```bash
# Add your GitHub repository as remote
# Replace YOUR_USERNAME with your GitHub username
git remote add origin https://github.com/YOUR_USERNAME/plastic-type-classification.git

# Check remote
git remote -v

# Push to GitHub
git branch -M main
git push -u origin main
```

**Enter your GitHub credentials when prompted.**

---

## ðŸ” GitHub Authentication

### Option A: Personal Access Token (Recommended)

1. Go to GitHub â†’ Settings â†’ Developer settings â†’ Personal access tokens
2. Click **"Generate new token (classic)"**
3. Select scopes: **repo** (full control)
4. Copy the token
5. When git asks for password, paste the token

### Option B: GitHub CLI

```bash
# Install GitHub CLI
brew install gh

# Authenticate
gh auth login

# Follow prompts
```

### Option C: SSH Key

```bash
# Generate SSH key
ssh-keygen -t ed25519 -C "your_email@example.com"

# Add to ssh-agent
eval "$(ssh-agent -s)"
ssh-add ~/.ssh/id_ed25519

# Copy public key
cat ~/.ssh/id_ed25519.pub

# Add to GitHub: Settings â†’ SSH keys â†’ New SSH key

# Use SSH remote instead
git remote set-url origin git@github.com:YOUR_USERNAME/plastic-type-classification.git
```

---

## ðŸ“¥ Clone in Google Colab

Once pushed to GitHub, you can clone directly in Colab:

### Method 1: Public Repository

```python
# In Colab cell
!git clone https://github.com/YOUR_USERNAME/plastic-type-classification.git
%cd plastic-type-classification
```

### Method 2: Private Repository

```python
# In Colab cell
from getpass import getpass
import os

# Get your Personal Access Token
token = getpass('Enter your GitHub token: ')

# Clone
!git clone https://{token}@github.com/YOUR_USERNAME/plastic-type-classification.git
%cd plastic-type-classification
```

### Method 3: Mount Drive + Clone

```python
# Best approach: Clone to Google Drive
from google.colab import drive
drive.mount('/content/drive')

%cd /content/drive/MyDrive/
!git clone https://github.com/YOUR_USERNAME/plastic-type-classification.git
%cd plastic-type-classification
```

---

## ðŸ”„ Sync Between Mac and Colab

### On Mac: Make changes and push

```bash
# Make changes to code
vim pipeline_train.py

# Stage and commit
git add pipeline_train.py
git commit -m "Improved training loop"

# Push to GitHub
git push
```

### On Colab: Pull latest changes

```python
# In Colab cell
%cd /content/drive/MyDrive/plastic-type-classification
!git pull

# Now you have the latest code!
```

---

## ðŸ“ What Gets Pushed to GitHub?

### âœ… Included (Code & Docs)
```
plastic-type-classification/
â”œâ”€â”€ pipeline_normalize.py
â”œâ”€â”€ pipeline_preprocess.py
â”œâ”€â”€ pipeline_dataset.py
â”œâ”€â”€ pipeline_model.py
â”œâ”€â”€ pipeline_train.py
â”œâ”€â”€ pipeline_inference.py
â”œâ”€â”€ run_pipeline_config.py
â”œâ”€â”€ config.py
â”œâ”€â”€ colab_pipeline.ipynb
â”œâ”€â”€ .gitignore
â”œâ”€â”€ README_PIPELINE.md
â”œâ”€â”€ COLAB_SETUP.md
â”œâ”€â”€ GITHUB_SETUP.md
â”œâ”€â”€ M4_GPU_SETUP.md
â”œâ”€â”€ GPU_AND_MODELS.md
â”œâ”€â”€ M4_TROUBLESHOOTING.md
â”œâ”€â”€ NORMALIZATION_OPTIONS.md
â”œâ”€â”€ SPATIAL_BINNING_FIX.md
â”œâ”€â”€ FLOAT64_FIX.md
â”œâ”€â”€ QUICK_START_M4.md
â””â”€â”€ FIXES_APPLIED.md
```

### âŒ Excluded (Data & Results)
```
# Too large - store on Google Drive instead
training_dataset/          # ~10 GB
Inference_dataset1/        # ~10 GB
Ground_Truth/              # ~5 MB (could include, but excluded for privacy)
training_dataset_normalized/
Inference_dataset1_normalized/
output/                    # Generated files
*.pth                      # Model weights (100+ MB)
```

---

## ðŸ“ Create a Great README

Create `README.md` in the root:

```bash
cat > README.md << 'EOF'
# Hyperspectral Plastic Classification

Complete pipeline for pixel-wise plastic classification from hyperspectral imagery using deep learning.

## Features

- ðŸŽ¯ **6 Model Architectures**: CNN, ResNet, Deep CNN, Inception, LSTM, Transformer
- âš¡ **GPU Accelerated**: Supports Apple Silicon M4 (MPS) and CUDA
- ðŸ“Š **11 Plastic Classes**: Background + 10 plastic types
- ðŸ”¬ **458 Spectral Bands**: 450-850nm wavelength range
- â˜ï¸ **Google Colab Ready**: Notebook included for cloud training

## Quick Start

### Local (Mac/Linux/Windows)
\`\`\`bash
python run_pipeline_config.py --mode full --model-type resnet --epochs 50
\`\`\`

### Google Colab
1. Open \`colab_pipeline.ipynb\` in Google Colab
2. Upload data to Google Drive
3. Run all cells

## Performance

| Platform | GPU | Training Time (50 epochs) |
|----------|-----|-------------------------|
| MacBook Air M4 | MPS | ~33 min |
| Google Colab Pro+ | A100 | ~6 min |

## Documentation

- [Quick Start (M4)](QUICK_START_M4.md)
- [Google Colab Setup](COLAB_SETUP.md)
- [GPU & Models Guide](GPU_AND_MODELS.md)
- [Complete Pipeline Docs](README_PIPELINE.md)

## Requirements

\`\`\`
torch>=2.0.0
torchvision
numpy
pillow
scipy
tqdm
matplotlib
\`\`\`

## Citation

If you use this pipeline, please cite:
\`\`\`
@software{hyperspectral_plastic_classification,
  title = {Hyperspectral Plastic Classification Pipeline},
  year = {2025},
  url = {https://github.com/YOUR_USERNAME/plastic-type-classification}
}
\`\`\`

## License

MIT License
EOF
```

Then commit and push:
```bash
git add README.md
git commit -m "Add README"
git push
```

---

## ðŸ·ï¸ Create requirements.txt

```bash
cat > requirements.txt << 'EOF'
torch>=2.0.0
torchvision>=0.15.0
numpy>=1.24.0
pillow>=10.0.0
scipy>=1.10.0
tqdm>=4.65.0
matplotlib>=3.7.0
EOF

git add requirements.txt
git commit -m "Add requirements.txt"
git push
```

---

## ðŸŒ¿ Branching Strategy

### For experiments:
```bash
# Create experiment branch
git checkout -b experiment/inception-model

# Make changes, commit
git add .
git commit -m "Experiment: Inception model with dropout 0.5"

# Push branch
git push -u origin experiment/inception-model

# Later, merge if successful
git checkout main
git merge experiment/inception-model
git push
```

---

## ðŸ“Š Example Workflow

### Day 1: Setup
```bash
# Mac
git init
git add .
git commit -m "Initial commit"
git push -u origin main
```

### Day 2: Train on Colab
```python
# Colab
!git clone https://github.com/YOUR_USERNAME/plastic-type-classification.git
# Upload data to Drive
# Run training
```

### Day 3: Improve on Mac
```bash
# Mac
git pull  # Get any Colab changes
# Make improvements
git add .
git commit -m "Improved preprocessing"
git push
```

### Day 4: Final training on Colab
```python
# Colab
!git pull  # Get Mac improvements
# Run final training
# Download results
```

---

## ðŸŽ¯ Best Practices

### 1. Commit Often
```bash
# After each significant change
git add .
git commit -m "Descriptive message"
git push
```

### 2. Use Meaningful Commit Messages
```bash
# âœ… Good
git commit -m "Fix spatial binning index error for MPS"

# âŒ Bad
git commit -m "fix bug"
```

### 3. Don't Commit Large Files
- Data files â†’ Google Drive
- Model weights â†’ Release or Drive
- Results â†’ Download locally

### 4. Keep .gitignore Updated
```bash
# Add new patterns as needed
echo "new_folder/" >> .gitignore
git add .gitignore
git commit -m "Update gitignore"
```

---

## ðŸš€ Ready to Push!

```bash
# Final checklist
git status                    # Verify files
git add .                     # Stage all
git commit -m "Initial commit"  # Commit
git push -u origin main       # Push

# Done! Your code is on GitHub! ðŸŽ‰
```

---

## ðŸ“– Next Steps

1. âœ… Push code to GitHub
2. âœ… Upload data to Google Drive (see [COLAB_SETUP.md](COLAB_SETUP.md))
3. âœ… Clone in Colab
4. âœ… Run training on Colab Pro+ A100
5. âœ… Enjoy 6x faster training! ðŸš€

---

## ðŸ†˜ Troubleshooting

### "Permission denied (publickey)"
â†’ Use HTTPS URL or setup SSH keys (see above)

### "Large files detected"
â†’ Check .gitignore, don't commit data folders

### "Authentication failed"
â†’ Use Personal Access Token instead of password

### "Nothing to commit"
â†’ Make sure files aren't in .gitignore

---

Your code is now version controlled, backed up, and ready to use on Google Colab! ðŸŽ‰
