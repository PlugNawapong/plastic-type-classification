{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperspectral Material Classification - Inference (Google Colab)\n",
    "\n",
    "Optimized for Google Colab Pro+ with A100 GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install spectral scikit-learn matplotlib tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Clone Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/PlugNawapong/hsi-deeplearning.git\n",
    "%cd hsi-deeplearning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "from pipeline_preprocess import HyperspectralPreprocessor\n",
    "from pipeline_model import create_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODIFY THESE PATHS to point to your Google Drive data\n",
    "CONFIG = {\n",
    "    'checkpoint_path': '/content/drive/MyDrive/outputs/colab/best_model.pth',\n",
    "    'data_path': '/content/drive/MyDrive/Inference_dataset1_normalized',\n",
    "    'output_dir': '/content/drive/MyDrive/outputs/inference',\n",
    "    'batch_size': 1024\n",
    "}\n",
    "\n",
    "print('Configuration:')\n",
    "for k, v in CONFIG.items():\n",
    "    print(f'  {k}: {v}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "# Load checkpoint\n",
    "checkpoint = torch.load(CONFIG['checkpoint_path'], map_location=device)\n",
    "train_config = checkpoint['config']\n",
    "\n",
    "# Create model\n",
    "model = create_model(\n",
    "    train_config['model_type'],\n",
    "    checkpoint['model_state_dict']['conv1.weight'].shape[1],\n",
    "    train_config['num_classes']\n",
    ")\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "print(f'Loaded model: {train_config[\"model_type\"]}')\n",
    "print(f'Validation accuracy: {checkpoint[\"val_acc\"]:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = HyperspectralPreprocessor(CONFIG['data_path'])\n",
    "data_cube = preprocessor.load_data()\n",
    "\n",
    "print(f'Data shape: {data_cube.shape}')\n",
    "height, width, bands = data_cube.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Run Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data\n",
    "pixels = data_cube.reshape(-1, bands)\n",
    "predictions = np.zeros(height * width, dtype=np.int32)\n",
    "confidences = np.zeros(height * width, dtype=np.float32)\n",
    "\n",
    "# Batch inference\n",
    "batch_size = CONFIG['batch_size']\n",
    "num_batches = (len(pixels) + batch_size - 1) // batch_size\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in tqdm(range(num_batches), desc='Inference'):\n",
    "        start_idx = i * batch_size\n",
    "        end_idx = min((i + 1) * batch_size, len(pixels))\n",
    "        \n",
    "        batch = torch.FloatTensor(pixels[start_idx:end_idx]).to(device)\n",
    "        outputs = model(batch)\n",
    "        probs = torch.softmax(outputs, dim=1)\n",
    "        \n",
    "        max_probs, preds = probs.max(1)\n",
    "        predictions[start_idx:end_idx] = preds.cpu().numpy()\n",
    "        confidences[start_idx:end_idx] = max_probs.cpu().numpy()\n",
    "\n",
    "# Reshape to image\n",
    "pred_map = predictions.reshape(height, width)\n",
    "conf_map = confidences.reshape(height, width)\n",
    "\n",
    "print(f'Inference complete!')\n",
    "print(f'Mean confidence: {conf_map.mean():.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Prediction map\n",
    "im1 = ax1.imshow(pred_map, cmap='tab10')\n",
    "ax1.set_title('Prediction Map')\n",
    "ax1.axis('off')\n",
    "plt.colorbar(im1, ax=ax1)\n",
    "\n",
    "# Confidence map\n",
    "im2 = ax2.imshow(conf_map, cmap='viridis', vmin=0, vmax=1)\n",
    "ax2.set_title('Confidence Map')\n",
    "ax2.axis('off')\n",
    "plt.colorbar(im2, ax=ax2)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Class Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, counts = np.unique(pred_map, return_counts=True)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.bar(unique, counts)\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Pixel Count')\n",
    "plt.title('Predicted Class Distribution')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print('\\nClass distribution:')\n",
    "for cls, cnt in zip(unique, counts):\n",
    "    print(f'  Class {cls}: {cnt:,} pixels ({100*cnt/predictions.size:.2f}%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = Path(CONFIG['output_dir'])\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save prediction and confidence maps\n",
    "np.save(output_dir / 'predictions.npy', pred_map)\n",
    "np.save(output_dir / 'confidences.npy', conf_map)\n",
    "\n",
    "# Save statistics\n",
    "stats = {\n",
    "    'mean_confidence': float(conf_map.mean()),\n",
    "    'class_distribution': {int(k): int(v) for k, v in zip(unique, counts)}\n",
    "}\n",
    "with open(output_dir / 'statistics.json', 'w') as f:\n",
    "    json.dump(stats, f, indent=2)\n",
    "\n",
    "print(f'Results saved to {output_dir}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Download Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "files.download(str(output_dir / 'predictions.npy'))\n",
    "files.download(str(output_dir / 'confidences.npy'))\n",
    "files.download(str(output_dir / 'statistics.json'))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}