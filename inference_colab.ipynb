{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperspectral Material Classification - Inference (Google Colab)\n",
    "\n",
    "Optimized for Google Colab Pro+ with A100 GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Check GPU and Install Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install spectral scikit-learn matplotlib tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Clone Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/PlugNawapong/hsi-deeplearning.git\n",
    "%cd hsi-deeplearning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "\n",
    "# Import pipeline functions and constants\n",
    "from pipeline_preprocess import load_hyperspectral_cube, preprocess_cube\n",
    "from pipeline_dataset import CLASS_NAMES, NUM_CLASSES  # Import class info from pipeline\n",
    "from pipeline_model import create_model\n",
    "\n",
    "print('Modules imported successfully!')\n",
    "print(f'Number of classes: {NUM_CLASSES}')\n",
    "print(f'Class names: {CLASS_NAMES}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Configuration\n",
    "\n",
    "**IMPORTANT:** All your data should be in the `DeepLearning_Plastics` folder in Google Drive:\n",
    "- Trained model: `DeepLearning_Plastics/outputs/colab/best_model.pth`\n",
    "- Inference data: `DeepLearning_Plastics/Inference_dataset1_normalized/` (or dataset2/dataset3)\n",
    "- Results will be saved to: `DeepLearning_Plastics/outputs/colab/inference_results/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration - Base directory: DeepLearning_Plastics in Google Drive\n",
    "BASE_DIR = '/content/drive/MyDrive/DeepLearning_Plastics'\n",
    "\n",
    "CONFIG = {\n",
    "    # Model path\n",
    "    'model_path': f'{BASE_DIR}/outputs/colab/best_model.pth',\n",
    "    \n",
    "    # Inference data - Change this to dataset2 or dataset3 as needed\n",
    "    'data_folder': f'{BASE_DIR}/Inference_dataset1_normalized',\n",
    "    \n",
    "    # Output directory\n",
    "    'output_dir': f'{BASE_DIR}/outputs/colab/inference_results',\n",
    "    \n",
    "    # Inference settings - Optimized for A100\n",
    "    'batch_size': 1024,  # Large batch size for A100\n",
    "    'num_workers': 4,\n",
    "}\n",
    "\n",
    "print('Configuration:')\n",
    "for k, v in CONFIG.items():\n",
    "    print(f'  {k}: {v}')\n",
    "print(f'\\nClass names (from labels.json): {CLASS_NAMES}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Load Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "# Load checkpoint\n",
    "print(f'\\nLoading model from: {CONFIG[\"model_path\"]}')\n",
    "checkpoint = torch.load(CONFIG['model_path'], map_location=device)\n",
    "\n",
    "# Get model configuration\n",
    "model_config = checkpoint['config']\n",
    "class_names = checkpoint.get('class_names', CLASS_NAMES)  # Use saved names or default to pipeline\n",
    "num_bands = checkpoint['num_bands']\n",
    "\n",
    "print(f'Model type: {model_config[\"model_type\"]}')\n",
    "print(f'Number of classes: {len(class_names)}')\n",
    "print(f'Classes: {class_names}')\n",
    "print(f'Number of bands: {num_bands}')\n",
    "print(f'Validation accuracy: {checkpoint[\"val_acc\"]:.2f}%')\n",
    "\n",
    "# Create model\n",
    "model = create_model(\n",
    "    num_bands=num_bands,\n",
    "    num_classes=len(class_names),\n",
    "    model_type=model_config['model_type'],\n",
    "    dropout_rate=model_config.get('dropout_rate', 0.5)\n",
    ")\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "print('\\n\u2713 Model loaded and ready for inference')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Load Inference Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load hyperspectral cube\n",
    "print(f'Loading hyperspectral cube from: {CONFIG[\"data_folder\"]}')\n",
    "cube, wavelengths, header = load_hyperspectral_cube(CONFIG['data_folder'])\n",
    "print(f'Cube shape: {cube.shape}')\n",
    "print(f'Wavelength range: {wavelengths[0]:.1f} - {wavelengths[-1]:.1f} nm')\n",
    "print(f'Number of bands: {len(wavelengths)}')\n",
    "\n",
    "# Apply preprocessing if needed (should match training)\n",
    "preprocess_config = model_config.get('preprocess', {})\n",
    "if any(preprocess_config.values()):\n",
    "    print('\\nApplying preprocessing...')\n",
    "    cube, wavelengths = preprocess_cube(cube, wavelengths, preprocess_config)\n",
    "    print(f'Processed shape: {cube.shape}')\n",
    "\n",
    "# Verify band count matches model\n",
    "if cube.shape[2] != num_bands:\n",
    "    raise ValueError(f'Band mismatch! Cube has {cube.shape[2]} bands, model expects {num_bands}')\n",
    "\n",
    "print('\\n\u2713 Data loaded successfully')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Run Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape for batch processing\n",
    "height, width, bands = cube.shape\n",
    "pixels = cube.reshape(-1, bands)\n",
    "print(f'Total pixels: {len(pixels):,}')\n",
    "\n",
    "# Run inference in batches\n",
    "all_predictions = []\n",
    "all_probabilities = []\n",
    "\n",
    "print(f'\\nRunning inference (batch size: {CONFIG[\"batch_size\"]})...')\n",
    "with torch.no_grad():\n",
    "    for i in tqdm(range(0, len(pixels), CONFIG['batch_size'])):\n",
    "        batch = pixels[i:i+CONFIG['batch_size']]\n",
    "        batch_tensor = torch.FloatTensor(batch).to(device)\n",
    "        \n",
    "        outputs = model(batch_tensor)\n",
    "        probabilities = torch.softmax(outputs, dim=1)\n",
    "        predictions = outputs.argmax(dim=1)\n",
    "        \n",
    "        all_predictions.extend(predictions.cpu().numpy())\n",
    "        all_probabilities.extend(probabilities.cpu().numpy())\n",
    "\n",
    "# Convert to arrays and reshape\n",
    "prediction_map = np.array(all_predictions).reshape(height, width)\n",
    "probability_maps = np.array(all_probabilities).reshape(height, width, len(class_names))\n",
    "\n",
    "print('\\n\u2713 Inference complete!')\n",
    "print(f'Prediction map shape: {prediction_map.shape}')\n",
    "print(f'Probability maps shape: {probability_maps.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Display Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create color map - automatically sized based on number of classes\n",
    "# Using a colorblind-friendly palette\n",
    "base_colors = [\n",
    "    [0, 0, 0],        # Background - Black\n",
    "    [230, 159, 0],    # Orange\n",
    "    [86, 180, 233],   # Sky Blue\n",
    "    [0, 158, 115],    # Bluish Green\n",
    "    [240, 228, 66],   # Yellow\n",
    "    [0, 114, 178],    # Blue\n",
    "    [213, 94, 0],     # Vermillion\n",
    "    [204, 121, 167],  # Reddish Purple\n",
    "    [255, 0, 0],      # Red\n",
    "    [0, 255, 0],      # Green\n",
    "    [255, 0, 255],    # Magenta\n",
    "]\n",
    "\n",
    "# Use only as many colors as we have classes\n",
    "colors = base_colors[:len(class_names)]\n",
    "\n",
    "# Create RGB visualization\n",
    "rgb_map = np.zeros((height, width, 3), dtype=np.uint8)\n",
    "for class_id, color in enumerate(colors):\n",
    "    mask = prediction_map == class_id\n",
    "    rgb_map[mask] = color\n",
    "\n",
    "# Calculate number of rows needed for probability maps (skip background)\n",
    "num_prob_maps = len(class_names) - 1  # Skip background\n",
    "num_cols = 4\n",
    "num_rows = (num_prob_maps + num_cols) // num_cols  # Ceiling division\n",
    "\n",
    "# Plot\n",
    "fig = plt.figure(figsize=(20, 5 * num_rows))\n",
    "gs = fig.add_gridspec(num_rows, num_cols)\n",
    "\n",
    "# Prediction map (larger, spans 2 columns)\n",
    "ax_main = fig.add_subplot(gs[0, :2])\n",
    "ax_main.imshow(rgb_map)\n",
    "ax_main.set_title('Classification Map', fontsize=14, fontweight='bold')\n",
    "ax_main.axis('off')\n",
    "\n",
    "# Probability maps for each class (skip background)\n",
    "for i in range(1, len(class_names)):\n",
    "    idx = i - 1  # Adjust for skipping background\n",
    "    if idx < 2:\n",
    "        row = 0\n",
    "        col = idx + 2\n",
    "    else:\n",
    "        row = (idx - 2) // num_cols + 1\n",
    "        col = (idx - 2) % num_cols\n",
    "    \n",
    "    ax = fig.add_subplot(gs[row, col])\n",
    "    im = ax.imshow(probability_maps[:, :, i], cmap='hot', vmin=0, vmax=1)\n",
    "    ax.set_title(f'{class_names[i]} Probability', fontsize=12)\n",
    "    ax.axis('off')\n",
    "    plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count pixels per class\n",
    "class_counts = Counter(prediction_map.flatten())\n",
    "total_pixels = prediction_map.size\n",
    "\n",
    "print('='*60)\n",
    "print('CLASSIFICATION STATISTICS')\n",
    "print('='*60)\n",
    "for class_id in range(len(class_names)):\n",
    "    count = class_counts.get(class_id, 0)\n",
    "    percentage = 100 * count / total_pixels\n",
    "    print(f'{class_names[class_id]:12s}: {count:8,} pixels ({percentage:5.2f}%)')\n",
    "print('='*60)\n",
    "print(f'{'Total':12s}: {total_pixels:8,} pixels (100.00%)')\n",
    "print('='*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directory\n",
    "output_dir = Path(CONFIG['output_dir'])\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save prediction map\n",
    "np.save(output_dir / 'prediction_map.npy', prediction_map)\n",
    "print(f'Saved: {output_dir}/prediction_map.npy')\n",
    "\n",
    "# Save probability maps\n",
    "np.save(output_dir / 'probability_maps.npy', probability_maps)\n",
    "print(f'Saved: {output_dir}/probability_maps.npy')\n",
    "\n",
    "# Save RGB visualization\n",
    "plt.figure(figsize=(12, 10))\n",
    "plt.imshow(rgb_map)\n",
    "plt.title('Classification Map', fontsize=16, fontweight='bold')\n",
    "plt.axis('off')\n",
    "\n",
    "# Add legend\n",
    "from matplotlib.patches import Patch\n",
    "legend_elements = [Patch(facecolor=np.array(color)/255, label=name) \n",
    "                   for name, color in zip(class_names, colors)]\n",
    "plt.legend(handles=legend_elements, loc='upper right', fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(output_dir / 'classification_map.png', dpi=150, bbox_inches='tight')\n",
    "print(f'Saved: {output_dir}/classification_map.png')\n",
    "\n",
    "# Save statistics\n",
    "stats = {\n",
    "    'class_names': class_names,\n",
    "    'class_counts': {class_names[i]: int(class_counts.get(i, 0)) for i in range(len(class_names))},\n",
    "    'total_pixels': int(total_pixels),\n",
    "    'image_shape': list(prediction_map.shape),\n",
    "    'model_type': model_config['model_type'],\n",
    "    'model_accuracy': float(checkpoint['val_acc'])\n",
    "}\n",
    "\n",
    "with open(output_dir / 'statistics.json', 'w') as f:\n",
    "    json.dump(stats, f, indent=2)\n",
    "print(f'Saved: {output_dir}/statistics.json')\n",
    "\n",
    "print(f'\\n\u2713 All results saved to: {output_dir}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Download Results (Optional)\n",
    "\n",
    "Results are already saved in Google Drive, but you can also download them directly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "# Uncomment to download\n",
    "# files.download(str(output_dir / 'prediction_map.npy'))\n",
    "# files.download(str(output_dir / 'probability_maps.npy'))\n",
    "# files.download(str(output_dir / 'classification_map.png'))\n",
    "# files.download(str(output_dir / 'statistics.json'))\n",
    "\n",
    "print(f'All results saved to Google Drive: {CONFIG[\"output_dir\"]}')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}